# UMU_5TF078_Paper_Keyboard_Tracker
### The use of CNN and ROI for classifying drawn keys

![Python](https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=blue) ![Tensorflow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white) ![Keras](https://img.shields.io/badge/Keras-FF0000?style=for-the-badge&logo=keras&logoColor=white) ![OpenCV](https://img.shields.io/badge/OpenCV-27338e?style=for-the-badge&logo=OpenCV&logoColor=white) ![LaTex](https://img.shields.io/badge/LaTeX-47A141?style=for-the-badge&logo=LaTeX&logoColor=white) ![NumPy](https://img.shields.io/badge/Numpy-777BB4?style=for-the-badge&logo=numpy&logoColor=white)

**This was the final project of the course [5TF078 Deep Learning - Methods and Applications](https://www.umu.se/utbildning/kurser/deep-learning---metoder-och-tillampningar/) at [Ume√• University](https://www.umu.se/) I took as an elective one while doing my main studies at [KTH Royal Institute of Technology](https://www.kth.se/en). The project was highly appriciahted by the teacher and gave a deeper understanding for implementations and limitations of machine learning and computer vision.**

"When using computers, as a rule, three types of input methods are used, keyboard, computer mouse (or trackpad on portable devices), and camera. These three have all been developed over a long time and come in different variants and features. But with today's great advances in AI and hardware, we can take this further without developing new computing accessories. By using the webcams we have and AI models together with existing algorithms for image processing, we can, among other things, replace or extend our keyboards with drawn ones. Adapted for just the right area of use."

**The introduction above is just a short section of the report written for this university project. The full report is available in Swedish in the folder "Rapport".**

## Exploring The Program
If you wish you test the program, just download the folder called "Program", install the libraries in "requirements.txt" and execute "main.py".

## Exploring The Model
To explore the model, go to the folder CNN. There you'll find all the necessary data including a "requirements.txt"-file which covers all the required libraries. Not that the data used is downloaded by the code written from a separate FTP-server due to file size limitations.

*Note that what's been uploaded so far is just the start of a longer project. No support for finger-tracking as been added so far.*
